name: CI & Deploy

on:
  push:
    branches:
      - main
  pull_request:

# Add proper permissions for the workflow
permissions:
  contents: read
  actions: write
  checks: write
  pull-requests: write

env:
  # Global environment variables shared across all jobs
  NODE_ENV: test
  CI: true
  SKIP_STRIPE_CLI: true
  # DATABASE_URL must be set for PostgreSQL testing
  CORS_ORIGIN: http://localhost:5173
  VITE_API_URL: http://localhost:8000
  STRIPE_WEBHOOK_SECRET: whsec_test_ci_webhook_secret_for_testing_only
  # Ensure consistent JWT secret for e2e tests
  JWT_SECRET: test-jwt-secret-for-e2e-tests

jobs:
  # Setup job - prepare dependencies and build
  setup:
    runs-on: ubuntu-latest
    outputs:
      # Cache key for sharing between jobs - simplified to avoid length issues
      cache-key: ${{ steps.cache-key.outputs.key }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'npm'
          
      - name: Generate cache key
        id: cache-key
        run: |
          # Create a shorter, more reliable cache key
          HASH=$(echo "${{ hashFiles('package-lock.json') }}" | cut -c1-8)
          echo "key=deps-${{ runner.os }}-node22-${HASH}" >> $GITHUB_OUTPUT
          
      - name: Install dependencies
        run: npm ci --silent --ignore-scripts
        
      # No need to rebuild native dependencies for PostgreSQL
        
      - name: Cache node_modules
        uses: actions/cache/save@v4
        with:
          path: |
            node_modules
            apps/*/node_modules
          key: ${{ steps.cache-key.outputs.key }}

  # Backend tests - fast unit tests
  test-backend:
    needs: setup
    runs-on: ubuntu-latest
    env:
      NEXTAUTH_SECRET: ${{ secrets.NEXTAUTH_SECRET }}
      STRIPE_SECRET_KEY: ${{ secrets.STRIPE_SECRET_KEY }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'npm'
          
      - name: Restore dependencies cache
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            apps/*/node_modules
          key: ${{ needs.setup.outputs.cache-key }}
          fail-on-cache-miss: true
          
      - name: Create test directories
        run: |
          mkdir -p tmp/test-results
          echo "Created tmp/test-results directory"
        
      - name: Prepare environment for PostgreSQL testing
        run: |
          echo "DATABASE_URL=${DATABASE_URL}" > .env
          echo "NEXTAUTH_SECRET=${NEXTAUTH_SECRET}" >> .env
          echo "CORS_ORIGIN=${CORS_ORIGIN}" >> .env
          echo "STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}" >> .env
          echo "STRIPE_WEBHOOK_SECRET=${STRIPE_WEBHOOK_SECRET}" >> .env
          echo "VITE_API_URL=${VITE_API_URL}" >> .env
          echo "CI=${CI}" >> .env
          echo "NODE_ENV=${NODE_ENV}" >> .env
          echo "SKIP_STRIPE_CLI=${SKIP_STRIPE_CLI}" >> .env
          echo "JWT_SECRET=${JWT_SECRET}" >> .env
          # PostgreSQL database approach
          echo "Using PostgreSQL database for backend tests"
        
      - name: Run backend unit tests
        run: npm run test:backend
        env:
          NODE_OPTIONS: "--max-old-space-size=2048"
          VITEST_SESSION_ID: backend-unit-ci-${{ github.run_id }}-${{ github.run_attempt }}
          CI: true
          
      - name: Check test results directory
        if: always()
        run: |
          echo "ðŸ“ Checking test results structure:"
          ls -la tmp/ || echo "tmp directory not found"
          ls -la tmp/test-results/ || echo "test-results directory not found"
          find tmp -name "*backend*" -type d || echo "No backend directories found"
          
      - name: Upload Backend Unit Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: backend-unit-test-results-with-databases
          path: |
            tmp/test-results/
            coverage/
            **/*.db
            **/*.sqlite
          retention-days: 14
          if-no-files-found: warn

  # Frontend tests - parallel execution
  test-frontend:
    needs: setup
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'npm'
          
      - name: Restore dependencies cache
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            apps/*/node_modules
          key: ${{ needs.setup.outputs.cache-key }}
          fail-on-cache-miss: true
          
      - name: Create test directories
        run: |
          mkdir -p tmp/test-results
          echo "Created tmp/test-results directory"
          
      - name: Run frontend tests
        run: |
          echo "ðŸŽ¨ Running frontend tests with session ID: frontend-ci-${{ github.run_id }}-${{ github.run_attempt }}"
          npm run test:frontend
        env:
          NODE_OPTIONS: "--max-old-space-size=4096"
          VITEST_SESSION_ID: frontend-ci-${{ github.run_id }}-${{ github.run_attempt }}
          CI: true
          
      - name: Check frontend test artifacts
        if: always()
        run: |
          echo "ðŸ“ Checking frontend test artifacts structure:"
          ls -la tmp/ || echo "tmp directory not found"
          ls -la tmp/test-results/ || echo "test-results directory not found"
          find tmp -name "*frontend*" -type d || echo "No frontend directories found"
          find . -name "coverage" -type d || echo "No coverage directories found"
          
      - name: Upload Frontend Coverage Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: frontend-coverage-report
          path: |
            tmp/test-results/
            coverage/
            apps/frontend/coverage/
          retention-days: 7
          if-no-files-found: warn

  # E2E tests - parallel execution with matrix strategy
  test-e2e:
    needs: setup
    runs-on: ubuntu-latest
    
    strategy:
      fail-fast: false
      matrix:
        # Parallel workers for test splitting
        shard: [1, 2, 3, 4]
        # Different browsers for comprehensive testing
        project: ['chromium', 'firefox', 'webkit']
        
    env:
      NEXTAUTH_SECRET: ${{ secrets.NEXTAUTH_SECRET }}
      STRIPE_SECRET_KEY: ${{ secrets.STRIPE_SECRET_KEY }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'npm'
          
      - name: Restore dependencies cache
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            apps/*/node_modules
          key: ${{ needs.setup.outputs.cache-key }}
          fail-on-cache-miss: true
          
      - name: Create test directories
        run: |
          mkdir -p tmp/test-results
          mkdir -p test-results
          mkdir -p playwright-report
          echo "Created test directories"
        
      - name: Prepare environment for PostgreSQL testing
        run: |
          echo "DATABASE_URL=${DATABASE_URL}" > .env
          echo "NEXTAUTH_SECRET=${NEXTAUTH_SECRET}" >> .env
          echo "CORS_ORIGIN=${CORS_ORIGIN}" >> .env
          echo "STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}" >> .env
          echo "STRIPE_WEBHOOK_SECRET=${STRIPE_WEBHOOK_SECRET}" >> .env
          echo "VITE_API_URL=${VITE_API_URL}" >> .env
          echo "CI=${CI}" >> .env
          echo "NODE_ENV=${NODE_ENV}" >> .env
          echo "SKIP_STRIPE_CLI=${SKIP_STRIPE_CLI}" >> .env
          echo "JWT_SECRET=${JWT_SECRET}" >> .env
          # PostgreSQL database approach for E2E tests
          echo "Using PostgreSQL database for E2E tests - shard ${{ matrix.shard }}"
          
      - name: Install Playwright browsers
        run: npx playwright install --with-deps ${{ matrix.project }}
        
      - name: Run E2E tests (shard ${{ matrix.shard }}/${{ strategy.job-total }}, ${{ matrix.project }})
        run: |
          PLAYWRIGHT_SESSION_ID=ci-${{ github.run_id }}-shard-${{ matrix.shard }} \
          npx playwright test \
            --project=${{ matrix.project }} \
            --shard=${{ matrix.shard }}/${{ strategy.job-total }} \
            --reporter=line,html
        env:
          PLAYWRIGHT_WORKERS: 2  # Allow 2 workers per shard for faster execution
          DEBUG: pw:api  # Enable verbose Playwright API logging
          CI: true
          
      - name: Check E2E artifacts
        if: always()
        run: |
          echo "ðŸ“ Checking for E2E artifacts:"
          ls -la . || true
          ls -la tmp/ || echo "tmp directory not found"
          ls -la tmp/test-results/ || echo "test-results directory not found"
          ls -la test-results/ || echo "test-results directory not found"
          ls -la playwright-report/ || echo "playwright-report directory not found"
          find . -name "*.db" -type f | head -10 || echo "No database files found"
          find . -name "*.sqlite" -type f | head -10 || echo "No SQLite files found"
          
      - name: Upload E2E Test Artifacts (${{ matrix.project }}-shard-${{ matrix.shard }})
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-${{ matrix.project }}-shard-${{ matrix.shard }}-with-db
          path: |
            tmp/test-results/
            test-results/
            playwright-report/
            **/*.db
            **/*.sqlite
          retention-days: 14
          if-no-files-found: warn

  # Consolidate E2E artifacts by browser
  consolidate-e2e-artifacts:
    needs: test-e2e
    runs-on: ubuntu-latest
    if: always()
    strategy:
      matrix:
        project: ['chromium', 'firefox', 'webkit']
    
    steps:
      - name: Download E2E artifacts with databases for ${{ matrix.project }}
        uses: actions/download-artifact@v4
        with:
          path: e2e-consolidated
          pattern: e2e-${{ matrix.project }}-*-with-db
          merge-multiple: true
          
      - name: Upload consolidated E2E artifacts for ${{ matrix.project }}
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results-${{ matrix.project }}
          path: e2e-consolidated/
          retention-days: 14
          if-no-files-found: warn
      
      # Clean up individual shard artifacts after consolidation
      - name: Delete shard artifacts for ${{ matrix.project }}
        uses: actions/github-script@v7
        if: always()
        continue-on-error: true
        with:
          script: |
            const owner = context.repo.owner;
            const repo = context.repo.repo;
            const runId = context.runId;
            
            try {
            // Get all artifacts for this workflow run
            const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
              owner,
              repo,
              run_id: runId,
            });
            
            // Delete shard-specific artifacts for this browser (with database files)
            for (const artifact of artifacts.data.artifacts) {
              if (artifact.name.startsWith('e2e-${{ matrix.project }}-shard-') && artifact.name.endsWith('-with-db')) {
                console.log(`Deleting artifact: ${artifact.name}`);
                await github.rest.actions.deleteArtifact({
                  owner,
                  repo,
                  artifact_id: artifact.id,
                });
              }
              }
            } catch (error) {
              console.log(`Error cleaning up artifacts: ${error.message}`);
            }

  # Collect and report results
  test-results:
    needs: [test-backend, test-frontend, test-e2e, consolidate-e2e-artifacts]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
          
      - name: Combine test results
        run: |
          echo "## Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Test results with status indicators
          backend_status="${{ needs.test-backend.result }}"
          frontend_status="${{ needs.test-frontend.result }}"
          e2e_status="${{ needs.test-e2e.result }}"
          
          # Set icons based on status
          backend_icon="âŒ"; [[ "$backend_status" == "success" ]] && backend_icon="âœ…"
          frontend_icon="âŒ"; [[ "$frontend_status" == "success" ]] && frontend_icon="âœ…"
          e2e_icon="âŒ"; [[ "$e2e_status" == "success" ]] && e2e_icon="âœ…"
          
          echo "| Test Suite | Status | Result |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|---------|" >> $GITHUB_STEP_SUMMARY
          echo "| Backend Unit | $backend_icon | $backend_status |" >> $GITHUB_STEP_SUMMARY
          echo "| Frontend | $frontend_icon | $frontend_status |" >> $GITHUB_STEP_SUMMARY
          echo "| E2E (3 browsers Ã— 4 shards) | $e2e_icon | $e2e_status |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Only show failures
          failures=()
          [[ "$backend_status" != "success" ]] && failures+=("Backend")
          [[ "$frontend_status" != "success" ]] && failures+=("Frontend")
          [[ "$e2e_status" != "success" ]] && failures+=("E2E")
          
          if [[ ${#failures[@]} -gt 0 ]]; then
            echo "### âš ï¸ Failed Test Suites" >> $GITHUB_STEP_SUMMARY
            for failure in "${failures[@]}"; do
              echo "- $failure tests require attention" >> $GITHUB_STEP_SUMMARY
            done
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Artifact summary (streamlined)
          echo "### ðŸ“¦ Artifacts Generated" >> $GITHUB_STEP_SUMMARY
          echo "- **E2E Results**: Consolidated by browser (chromium, firefox, webkit) with per-file databases" >> $GITHUB_STEP_SUMMARY
          echo "- **Coverage Reports**: Backend + Frontend (auto-enabled in CI)" >> $GITHUB_STEP_SUMMARY
          echo "- **Per-File Databases**: Each test creates isolated database files (no sharing conflicts)" >> $GITHUB_STEP_SUMMARY
          echo "- **Backend Test Databases**: Per-file isolated SQLite databases for debugging" >> $GITHUB_STEP_SUMMARY
          
      - name: Check overall success
        run: |
          if [[ "${{ needs.test-backend.result }}" != "success" ]] || 
             [[ "${{ needs.test-frontend.result }}" != "success" ]] || 
             [[ "${{ needs.test-e2e.result }}" != "success" ]]; then
            echo "Some tests failed"
            exit 1
          fi
          echo "All tests passed!"

